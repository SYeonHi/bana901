{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoo8kfSYBaCn6bOsr68JIV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SYeonHi/bana901/blob/main/ai%EB%8C%80%ED%9A%8C_07021667.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "Wlpw_05PVMAk",
        "outputId": "4366ce33-5878-450f-ab5d-4f41816a78dd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torchmetrics'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-bf46d7211b07>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchmetrics'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import librosa\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torchmetrics\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "-iIGKgvRViAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "x-zrCl4cVysj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    SR = 32000\n",
        "    N_MFCC = 13\n",
        "    # Dataset\n",
        "    ROOT_FOLDER = './'\n",
        "    # Training\n",
        "    N_CLASSES = 2\n",
        "    BATCH_SIZE = 96\n",
        "    N_EPOCHS = 5\n",
        "    LR = 3e-4\n",
        "    # Others\n",
        "    SEED = 42\n",
        "\n",
        "CONFIG = Config()"
      ],
      "metadata": {
        "id": "dTZBTeHZV450"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(CONFIG.SEED) # Seed 고정"
      ],
      "metadata": {
        "id": "w3ivBx6hV6DJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('./train.csv')\n",
        "train, val, _, _ = train_test_split(df, df['label'], test_size=0.2, random_state=CONFIG.SEED)"
      ],
      "metadata": {
        "id": "zPQw3pLUV7KV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mfcc_feature(df, train_mode=True):\n",
        "    features = []\n",
        "    labels = []\n",
        "    for _, row in tqdm(df.iterrows()):\n",
        "        # librosa패키지를 사용하여 wav 파일 load\n",
        "        y, sr = librosa.load(row['path'], sr=CONFIG.SR)\n",
        "\n",
        "        # librosa패키지를 사용하여 mfcc 추출\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=CONFIG.N_MFCC)\n",
        "        mfcc = np.mean(mfcc.T, axis=0)\n",
        "        features.append(mfcc)\n",
        "\n",
        "        if train_mode:\n",
        "            label = row['label']\n",
        "            label_vector = np.zeros(CONFIG.N_CLASSES, dtype=float)\n",
        "            label_vector[0 if label == 'fake' else 1] = 1\n",
        "            labels.append(label_vector)\n",
        "\n",
        "    if train_mode:\n",
        "        return features, labels\n",
        "    return features"
      ],
      "metadata": {
        "id": "FQBsPKbKV8HA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mfcc, train_labels = get_mfcc_feature(train, True)\n",
        "val_mfcc, val_labels = get_mfcc_feature(val, True)"
      ],
      "metadata": {
        "id": "ujX0ppF8V9PT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, mfcc, label):\n",
        "        self.mfcc = mfcc\n",
        "        self.label = label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.mfcc)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.label is not None:\n",
        "            return self.mfcc[index], self.label[index]\n",
        "        return self.mfcc[index]"
      ],
      "metadata": {
        "id": "rH6y1oK3V97J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(train_mfcc, train_labels)\n",
        "val_dataset = CustomDataset(val_mfcc, val_labels)"
      ],
      "metadata": {
        "id": "UCVz1cFLWBeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=CONFIG.BATCH_SIZE,\n",
        "    shuffle=True\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=CONFIG.BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "NZRRIyaUWCk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim=CONFIG.N_MFCC, hidden_dim=128, output_dim=CONFIG.N_CLASSES):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Y6d--xjIWDUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def train(model, optimizer, train_loader, val_loader, device):\n",
        "    model.to(device)\n",
        "    criterion = nn.BCELoss().to(device)\n",
        "\n",
        "    best_val_score = 0\n",
        "    best_model = None\n",
        "\n",
        "    for epoch in range(1, CONFIG.N_EPOCHS+1):\n",
        "        model.train()\n",
        "        train_loss = []\n",
        "        for features, labels in tqdm(iter(train_loader)):\n",
        "            features = features.float().to(device)\n",
        "            labels = labels.float().to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(features)\n",
        "            loss = criterion(output, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss.append(loss.item())\n",
        "\n",
        "        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n",
        "        _train_loss = np.mean(train_loss)\n",
        "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val AUC : [{_val_score:.5f}]')\n",
        "\n",
        "        if best_val_score < _val_score:\n",
        "            best_val_score = _val_score\n",
        "            best_model = model\n",
        "\n",
        "    return best_model\n",
        "\n",
        "def multiLabel_AUC(y_true, y_scores):\n",
        "    auc_scores = []\n",
        "    for i in range(y_true.shape[1]):\n",
        "        auc = roc_auc_score(y_true[:, i], y_scores[:, i])\n",
        "        auc_scores.append(auc)\n",
        "    mean_auc_score = np.mean(auc_scores)\n",
        "    return mean_auc_score\n",
        "\n",
        "def validation(model, criterion, val_loader, device):\n",
        "    model.eval()\n",
        "    val_loss, all_labels, all_probs = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for features, labels in tqdm(iter(val_loader)):\n",
        "            features = features.float().to(device)\n",
        "            labels = labels.float().to(device)\n",
        "\n",
        "            probs = model(features)\n",
        "\n",
        "            loss = criterion(probs, labels)\n",
        "\n",
        "            val_loss.append(loss.item())\n",
        "\n",
        "            all_labels.append(labels.cpu().numpy())\n",
        "            all_probs.append(probs.cpu().numpy())\n",
        "\n",
        "        _val_loss = np.mean(val_loss)\n",
        "\n",
        "        all_labels = np.concatenate(all_labels, axis=0)\n",
        "        all_probs = np.concatenate(all_probs, axis=0)\n",
        "\n",
        "        # Calculate AUC score\n",
        "        auc_score = multiLabel_AUC(all_labels, all_probs)\n",
        "\n",
        "    return _val_loss, auc_score"
      ],
      "metadata": {
        "id": "aWGs4YKrWFYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP()\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = CONFIG.LR)\n",
        "\n",
        "infer_model = train(model, optimizer, train_loader, val_loader, device)"
      ],
      "metadata": {
        "id": "E5W5iUS6WGh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('./test.csv')\n",
        "test_mfcc = get_mfcc_feature(test, False)\n",
        "test_dataset = CustomDataset(test_mfcc, None)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=CONFIG.BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "4OpNtxCxWHcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(model, test_loader, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for features in tqdm(iter(test_loader)):\n",
        "            features = features.float().to(device)\n",
        "\n",
        "            probs = model(features)\n",
        "\n",
        "            probs  = probs.cpu().detach().numpy()\n",
        "            predictions += probs.tolist()\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "NbYjG0G8WI-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = inference(infer_model, test_loader, device)"
      ],
      "metadata": {
        "id": "rjIQXAFsWIWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.read_csv('./sample_submission.csv')\n",
        "submit.iloc[:, 1:] = preds\n",
        "submit.head()"
      ],
      "metadata": {
        "id": "pnQvZvgrWKXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit.to_csv('./baseline_submit.csv', index=False)"
      ],
      "metadata": {
        "id": "poGkzyO6WM36"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}